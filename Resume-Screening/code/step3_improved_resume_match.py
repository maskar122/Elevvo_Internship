import pandas as pd
import numpy as np
import re
from sentence_transformers import SentenceTransformer, util

# ===== Ù…Ø³Ø§Ø± Ù…Ù„Ù Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ© Ø§Ù„Ù…Ù†Ø¸Ù‘Ù =====
DATA_PATH = r"C:\Users\LAP-STORE\Desktop\Amit\NLP_Intern\Resume Screening\artifacts\resumes_cleaned.csv"
# ============================================

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
df = pd.read_csv(DATA_PATH)

# ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø£Ù‚ÙˆÙ‰ (Ø£Ø¯Ù‚ Ù…Ù† all-MiniLM)
model = SentenceTransformer('multi-qa-mpnet-base-dot-v1')

# ÙˆØµÙ Ø§Ù„ÙˆØ¸ÙŠÙØ© - Ø¹Ø¯Ù‘Ù„ Ø­Ø³Ø¨ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨
job_description = """
Job Role: Financial Accountant
Responsibilities: financial reporting, budgeting, and auditing.
Skills: accounting, GAAP, Excel, SAP, ERP systems, financial analysis, reconciliation, cost control.
Experience: 3-5 years of experience in corporate finance.
Education: Bachelor's degree in Accounting or Finance.
"""

# ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù€ embedding Ù„ÙˆØµÙ Ø§Ù„ÙˆØ¸ÙŠÙØ©
job_embedding = model.encode(job_description, convert_to_tensor=True)

def split_into_chunks(text, words_per_chunk=200):
    """ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ù…Ù‚Ø§Ø·Ø¹ ØµØºÙŠØ±Ø© Ù„Ø±ÙØ¹ Ø¯Ù‚Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡"""
    words = text.split()
    return [" ".join(words[i:i+words_per_chunk]) for i in range(0, len(words), words_per_chunk)]

results = []

print("ğŸ”„ Generating embeddings and calculating similarity...")

for idx, row in df.iterrows():
    text = str(row['clean_text'])
    chunks = split_into_chunks(text)

    # ØªØ­ÙˆÙŠÙ„ ÙƒÙ„ chunk Ø¥Ù„Ù‰ embedding
    chunk_embeddings = model.encode(chunks, convert_to_tensor=True)

    # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ù„ÙƒÙ„ Ù…Ù‚Ø·Ø¹ ÙˆØ£Ø®Ø° Ø§Ù„Ø£Ø¹Ù„Ù‰
    cosine_scores = util.cos_sim(job_embedding, chunk_embeddings)[0]
    best_score = float(cosine_scores.max())

    results.append({
        'filename': row['filename'],
        'category': row['category'],
        'best_score': best_score,
    })

# ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¥Ù„Ù‰ DataFrame
res_df = pd.DataFrame(results)
res_df = res_df.sort_values(by='best_score', ascending=False).reset_index(drop=True)

# Ø¹Ø±Ø¶ Ø£Ø¹Ù„Ù‰ 5
print("\nğŸ† Top 5 Matching Resumes:")
for i in range(5):
    print(f"{i+1}. File: {res_df.iloc[i]['filename']} | Category: {res_df.iloc[i]['category']} | Score: {res_df.iloc[i]['best_score']:.4f}")

# Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ CSV
res_df.to_csv(r"C:\Users\LAP-STORE\Desktop\Amit\NLP_Intern\Resume Screening\artifacts\resume_similarity_scores_final.csv", index=False)
print("\nâœ… Results saved to artifacts/resume_similarity_scores.csv")

# ======================================================
# ğŸ§  Ø­ÙØ¸ Ø§Ù„Ù€ embeddings Ø¹Ù„Ø´Ø§Ù† ØªØ³ØªØ®Ø¯Ù…Ù‡Ø§ ÙÙŠ Streamlit
# ======================================================

print("\nğŸ’¾ Generating and saving resume embeddings for future use...")

# Ø­Ø³Ø§Ø¨ embeddings Ù„ÙƒÙ„ Ø§Ù„Ø³ÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠØ© Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø·
all_texts = df["clean_text"].tolist()
resume_embeddings = model.encode(all_texts, batch_size=16, show_progress_bar=True)

# Ø­ÙØ¸ embeddings + filenames + categories ÙÙŠ Ù…Ù„Ù ÙˆØ§Ø­Ø¯
np.savez(
    r"C:\Users\LAP-STORE\Desktop\Amit\NLP_Intern\Resume Screening\artifacts\resume_embeddings.npz",
    embeddings=resume_embeddings,
    filenames=df["filename"].tolist(),
    categories=df["category"].tolist()
)

print("âœ… Embeddings saved successfully to artifacts/resume_embeddings.npz")
